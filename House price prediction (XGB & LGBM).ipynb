{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52570575",
   "metadata": {
    "papermill": {
     "duration": 0.00826,
     "end_time": "2024-10-07T20:52:25.840570",
     "exception": false,
     "start_time": "2024-10-07T20:52:25.832310",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a597405b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:25.856040Z",
     "iopub.status.busy": "2024-10-07T20:52:25.855505Z",
     "iopub.status.idle": "2024-10-07T20:52:26.791010Z",
     "shell.execute_reply": "2024-10-07T20:52:26.789823Z"
    },
    "papermill": {
     "duration": 0.946372,
     "end_time": "2024-10-07T20:52:26.793583",
     "exception": false,
     "start_time": "2024-10-07T20:52:25.847211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n",
      "/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c891a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:26.808433Z",
     "iopub.status.busy": "2024-10-07T20:52:26.807828Z",
     "iopub.status.idle": "2024-10-07T20:52:28.562474Z",
     "shell.execute_reply": "2024-10-07T20:52:28.561023Z"
    },
    "papermill": {
     "duration": 1.765085,
     "end_time": "2024-10-07T20:52:28.565240",
     "exception": false,
     "start_time": "2024-10-07T20:52:26.800155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['house-prices-advanced-regression-techniques']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "print(os.listdir(\"/kaggle/input\"))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bcc9416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:28.580628Z",
     "iopub.status.busy": "2024-10-07T20:52:28.579630Z",
     "iopub.status.idle": "2024-10-07T20:52:28.662384Z",
     "shell.execute_reply": "2024-10-07T20:52:28.661328Z"
    },
    "papermill": {
     "duration": 0.093344,
     "end_time": "2024-10-07T20:52:28.665153",
     "exception": false,
     "start_time": "2024-10-07T20:52:28.571809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train  = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n",
    "test   = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n",
    "sample = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2619c6c",
   "metadata": {
    "papermill": {
     "duration": 0.006694,
     "end_time": "2024-10-07T20:52:28.678448",
     "exception": false,
     "start_time": "2024-10-07T20:52:28.671754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65701664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:28.694413Z",
     "iopub.status.busy": "2024-10-07T20:52:28.693923Z",
     "iopub.status.idle": "2024-10-07T20:52:28.699139Z",
     "shell.execute_reply": "2024-10-07T20:52:28.697953Z"
    },
    "papermill": {
     "duration": 0.015736,
     "end_time": "2024-10-07T20:52:28.701664",
     "exception": false,
     "start_time": "2024-10-07T20:52:28.685928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#can be used if we import pandas_profiling as pp\n",
    "#pp.ProfileReport(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ad00824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:28.717004Z",
     "iopub.status.busy": "2024-10-07T20:52:28.716574Z",
     "iopub.status.idle": "2024-10-07T20:52:28.722322Z",
     "shell.execute_reply": "2024-10-07T20:52:28.721238Z"
    },
    "papermill": {
     "duration": 0.016205,
     "end_time": "2024-10-07T20:52:28.724997",
     "exception": false,
     "start_time": "2024-10-07T20:52:28.708792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function for viewing data with max 1000 columns and rows\n",
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4517dd70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:28.740237Z",
     "iopub.status.busy": "2024-10-07T20:52:28.739151Z",
     "iopub.status.idle": "2024-10-07T20:52:28.758726Z",
     "shell.execute_reply": "2024-10-07T20:52:28.757447Z"
    },
    "papermill": {
     "duration": 0.0298,
     "end_time": "2024-10-07T20:52:28.761352",
     "exception": false,
     "start_time": "2024-10-07T20:52:28.731552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Seprate taget value \"Id\" \"Saleprice(more importantly)\" from the features\n",
    "y     = train[['Id','SalePrice']]\n",
    "#After storing the target value \"SalePrice\" in y we can now drop it from the feature set \n",
    "train = train.drop('SalePrice',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e345dfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:28.776203Z",
     "iopub.status.busy": "2024-10-07T20:52:28.775791Z",
     "iopub.status.idle": "2024-10-07T20:52:28.796309Z",
     "shell.execute_reply": "2024-10-07T20:52:28.795096Z"
    },
    "papermill": {
     "duration": 0.030822,
     "end_time": "2024-10-07T20:52:28.798918",
     "exception": false,
     "start_time": "2024-10-07T20:52:28.768096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creates a list with both Training and Testing Data sets -> all_dfs\n",
    "all_dfs = [train,test]\n",
    "# \"d.concat(all_dfs)\" merges the train and test datasets into a single DataFrame called all_df. It stacks them vertically by default since they share the same columns.\n",
    "# \".reset_index(drop=True)\" resets the index of the new concatenated DataFrame and drops the old index. \n",
    "# Without this, the concatenated DataFrame would retain the indices from both train and test\n",
    "all_df = pd.concat(all_dfs).reset_index(drop=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bafbf967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:28.813330Z",
     "iopub.status.busy": "2024-10-07T20:52:28.812891Z",
     "iopub.status.idle": "2024-10-07T20:52:28.834191Z",
     "shell.execute_reply": "2024-10-07T20:52:28.832810Z"
    },
    "papermill": {
     "duration": 0.031241,
     "end_time": "2024-10-07T20:52:28.836528",
     "exception": false,
     "start_time": "2024-10-07T20:52:28.805287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                0.000000\n",
       "MSSubClass        0.000000\n",
       "MSZoning          0.137033\n",
       "LotFrontage      16.649538\n",
       "LotArea           0.000000\n",
       "Street            0.000000\n",
       "Alley            93.216855\n",
       "LotShape          0.000000\n",
       "LandContour       0.000000\n",
       "Utilities         0.068517\n",
       "LotConfig         0.000000\n",
       "LandSlope         0.000000\n",
       "Neighborhood      0.000000\n",
       "Condition1        0.000000\n",
       "Condition2        0.000000\n",
       "BldgType          0.000000\n",
       "HouseStyle        0.000000\n",
       "OverallQual       0.000000\n",
       "OverallCond       0.000000\n",
       "YearBuilt         0.000000\n",
       "YearRemodAdd      0.000000\n",
       "RoofStyle         0.000000\n",
       "RoofMatl          0.000000\n",
       "Exterior1st       0.034258\n",
       "Exterior2nd       0.034258\n",
       "MasVnrType       60.500171\n",
       "MasVnrArea        0.787941\n",
       "ExterQual         0.000000\n",
       "ExterCond         0.000000\n",
       "Foundation        0.000000\n",
       "BsmtQual          2.774923\n",
       "BsmtCond          2.809181\n",
       "BsmtExposure      2.809181\n",
       "BsmtFinType1      2.706406\n",
       "BsmtFinSF1        0.034258\n",
       "BsmtFinType2      2.740665\n",
       "BsmtFinSF2        0.034258\n",
       "BsmtUnfSF         0.034258\n",
       "TotalBsmtSF       0.034258\n",
       "Heating           0.000000\n",
       "HeatingQC         0.000000\n",
       "CentralAir        0.000000\n",
       "Electrical        0.034258\n",
       "1stFlrSF          0.000000\n",
       "2ndFlrSF          0.000000\n",
       "LowQualFinSF      0.000000\n",
       "GrLivArea         0.000000\n",
       "BsmtFullBath      0.068517\n",
       "BsmtHalfBath      0.068517\n",
       "FullBath          0.000000\n",
       "HalfBath          0.000000\n",
       "BedroomAbvGr      0.000000\n",
       "KitchenAbvGr      0.000000\n",
       "KitchenQual       0.034258\n",
       "TotRmsAbvGrd      0.000000\n",
       "Functional        0.068517\n",
       "Fireplaces        0.000000\n",
       "FireplaceQu      48.646797\n",
       "GarageType        5.378554\n",
       "GarageYrBlt       5.447071\n",
       "GarageFinish      5.447071\n",
       "GarageCars        0.034258\n",
       "GarageArea        0.034258\n",
       "GarageQual        5.447071\n",
       "GarageCond        5.447071\n",
       "PavedDrive        0.000000\n",
       "WoodDeckSF        0.000000\n",
       "OpenPorchSF       0.000000\n",
       "EnclosedPorch     0.000000\n",
       "3SsnPorch         0.000000\n",
       "ScreenPorch       0.000000\n",
       "PoolArea          0.000000\n",
       "PoolQC           99.657417\n",
       "Fence            80.438506\n",
       "MiscFeature      96.402878\n",
       "MiscVal           0.000000\n",
       "MoSold            0.000000\n",
       "YrSold            0.000000\n",
       "SaleType          0.034258\n",
       "SaleCondition     0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all((all_df.isnull().sum()/all_df.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a19e32",
   "metadata": {
    "papermill": {
     "duration": 0.006284,
     "end_time": "2024-10-07T20:52:28.849248",
     "exception": false,
     "start_time": "2024-10-07T20:52:28.842964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Handling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c90311f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:28.864420Z",
     "iopub.status.busy": "2024-10-07T20:52:28.863960Z",
     "iopub.status.idle": "2024-10-07T20:52:28.872798Z",
     "shell.execute_reply": "2024-10-07T20:52:28.871522Z"
    },
    "papermill": {
     "duration": 0.019621,
     "end_time": "2024-10-07T20:52:28.875498",
     "exception": false,
     "start_time": "2024-10-07T20:52:28.855877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop all the features with very high number in null rows \n",
    "all_df.drop(['Alley','PoolQC','MiscFeature','Fence','FireplaceQu','Utilities'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f813a87b",
   "metadata": {
    "papermill": {
     "duration": 0.006263,
     "end_time": "2024-10-07T20:52:28.888355",
     "exception": false,
     "start_time": "2024-10-07T20:52:28.882092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Importance of Filling Missing Values:\n",
    "* **Model Performance**: Many machine learning algorithms do not handle missing values well, and filling them in can help improve model accuracy.\n",
    "* **Data Integrity**: Ensuring that all necessary fields are filled helps maintain the integrity of the dataset, allowing for a more comprehensive analysis.\n",
    "* **Bias Mitigation**: Using medians for numerical values can help reduce bias in your model, particularly in the presence of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73b73e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:28.903141Z",
     "iopub.status.busy": "2024-10-07T20:52:28.902745Z",
     "iopub.status.idle": "2024-10-07T20:52:28.931237Z",
     "shell.execute_reply": "2024-10-07T20:52:28.929986Z"
    },
    "papermill": {
     "duration": 0.040121,
     "end_time": "2024-10-07T20:52:28.934891",
     "exception": false,
     "start_time": "2024-10-07T20:52:28.894770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/451540263.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['LotFrontage'].fillna(value=all_df['LotFrontage'].median(),inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['MasVnrType'].fillna(value='None',inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['MasVnrArea'].fillna(0,inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['BsmtCond'].fillna(value='TA',inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['BsmtExposure'].fillna(value='No',inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['Electrical'].fillna(value='SBrkr',inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['BsmtFinType2'].fillna(value='Unf',inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['GarageType'].fillna(value='Attchd',inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['GarageYrBlt'].fillna(value=all_df['GarageYrBlt'].median(),inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['GarageFinish'].fillna(value='Unf',inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['GarageQual'].fillna(value='TA',inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['GarageCond'].fillna(value='TA',inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['BsmtFinType1'].fillna(value='NO',inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['BsmtQual'].fillna(value='No',inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['BsmtFullBath'].fillna(value=all_df['BsmtFullBath'].median(),inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['BsmtFinSF1'].fillna(value=all_df['BsmtFinSF1'].median(),inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['BsmtFinSF2'].fillna(value=0,inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['BsmtUnfSF'].fillna(value=0,inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['TotalBsmtSF'].fillna(value=all_df['TotalBsmtSF'].median(),inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['BsmtHalfBath'].fillna(value=0,inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['GarageCars'].fillna(value=all_df['GarageCars'].median(),inplace=True)\n",
      "/tmp/ipykernel_17/451540263.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df['GarageArea'].fillna(value=all_df['GarageArea'].median(),inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# with all feature with few null views, we manually filled the missing data\n",
    "all_df['LotFrontage'].fillna(value=all_df['LotFrontage'].median(),inplace=True)\n",
    "all_df['MasVnrType'].fillna(value='None',inplace=True)\n",
    "all_df['MasVnrArea'].fillna(0,inplace=True)\n",
    "all_df['BsmtCond'].fillna(value='TA',inplace=True)\n",
    "all_df['BsmtExposure'].fillna(value='No',inplace=True)\n",
    "all_df['Electrical'].fillna(value='SBrkr',inplace=True)\n",
    "all_df['BsmtFinType2'].fillna(value='Unf',inplace=True)\n",
    "all_df['GarageType'].fillna(value='Attchd',inplace=True)\n",
    "all_df['GarageYrBlt'].fillna(value=all_df['GarageYrBlt'].median(),inplace=True)\n",
    "all_df['GarageFinish'].fillna(value='Unf',inplace=True)\n",
    "all_df['GarageQual'].fillna(value='TA',inplace=True)\n",
    "all_df['GarageCond'].fillna(value='TA',inplace=True)\n",
    "all_df['BsmtFinType1'].fillna(value='NO',inplace=True)\n",
    "all_df['BsmtQual'].fillna(value='No',inplace=True)\n",
    "all_df['BsmtFullBath'].fillna(value=all_df['BsmtFullBath'].median(),inplace=True)\n",
    "all_df['BsmtFinSF1'].fillna(value=all_df['BsmtFinSF1'].median(),inplace=True)\n",
    "all_df['BsmtFinSF2'].fillna(value=0,inplace=True)\n",
    "all_df['BsmtUnfSF'].fillna(value=0,inplace=True)\n",
    "all_df['TotalBsmtSF'].fillna(value=all_df['TotalBsmtSF'].median(),inplace=True)\n",
    "all_df['BsmtHalfBath'].fillna(value=0,inplace=True)\n",
    "all_df['GarageCars'].fillna(value=all_df['GarageCars'].median(),inplace=True)\n",
    "all_df['GarageArea'].fillna(value=all_df['GarageArea'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d76e4fa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:28.950843Z",
     "iopub.status.busy": "2024-10-07T20:52:28.950394Z",
     "iopub.status.idle": "2024-10-07T20:52:29.007062Z",
     "shell.execute_reply": "2024-10-07T20:52:29.005955Z"
    },
    "papermill": {
     "duration": 0.067988,
     "end_time": "2024-10-07T20:52:29.009803",
     "exception": false,
     "start_time": "2024-10-07T20:52:28.941815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Using labelencoder from Ssklearn to convert \"categorical features\" to to a numerical format\n",
    "#This step is essential before feeding the data into Machine Learning models since they work better with numerical input\n",
    "labelencoder=LabelEncoder()\n",
    "\n",
    "all_df['MSZoning']      = labelencoder.fit_transform(all_df['MSZoning'].astype(str))\n",
    "all_df['Exterior1st']   = labelencoder.fit_transform(all_df['Exterior1st'].astype(str))\n",
    "all_df['Exterior2nd']   = labelencoder.fit_transform(all_df['Exterior2nd'].astype(str))\n",
    "all_df['KitchenQual']   = labelencoder.fit_transform(all_df['KitchenQual'].astype(str))\n",
    "all_df['Functional']    = labelencoder.fit_transform(all_df['Functional'].astype(str))\n",
    "all_df['SaleType']      = labelencoder.fit_transform(all_df['SaleType'].astype(str))\n",
    "all_df['Street']        = labelencoder.fit_transform(all_df['Street'])   \n",
    "all_df['LotShape']      = labelencoder.fit_transform(all_df['LotShape'])   \n",
    "all_df['LandContour']   = labelencoder.fit_transform(all_df['LandContour'])   \n",
    "all_df['LotConfig']     = labelencoder.fit_transform(all_df['LotConfig'])   \n",
    "all_df['LandSlope']     = labelencoder.fit_transform(all_df['LandSlope'])   \n",
    "all_df['Neighborhood']  = labelencoder.fit_transform(all_df['Neighborhood'])   \n",
    "all_df['Condition1']    = labelencoder.fit_transform(all_df['Condition1'])   \n",
    "all_df['Condition2']    = labelencoder.fit_transform(all_df['Condition2'])   \n",
    "all_df['BldgType']      = labelencoder.fit_transform(all_df['BldgType'])   \n",
    "all_df['HouseStyle']    = labelencoder.fit_transform(all_df['HouseStyle'])   \n",
    "all_df['RoofStyle']     = labelencoder.fit_transform(all_df['RoofStyle'])   \n",
    "all_df['RoofMatl']      = labelencoder.fit_transform(all_df['RoofMatl'])    \n",
    "all_df['MasVnrType']    = labelencoder.fit_transform(all_df['MasVnrType'])   \n",
    "all_df['ExterQual']     = labelencoder.fit_transform(all_df['ExterQual'])  \n",
    "all_df['ExterCond']     = labelencoder.fit_transform(all_df['ExterCond'])   \n",
    "all_df['Foundation']    = labelencoder.fit_transform(all_df['Foundation'])   \n",
    "all_df['BsmtQual']      = labelencoder.fit_transform(all_df['BsmtQual'])   \n",
    "all_df['BsmtCond']      = labelencoder.fit_transform(all_df['BsmtCond'])   \n",
    "all_df['BsmtExposure']  = labelencoder.fit_transform(all_df['BsmtExposure'])   \n",
    "all_df['BsmtFinType1']  = labelencoder.fit_transform(all_df['BsmtFinType1'])   \n",
    "all_df['BsmtFinType2']  = labelencoder.fit_transform(all_df['BsmtFinType2'])   \n",
    "all_df['Heating']       = labelencoder.fit_transform(all_df['Heating'])   \n",
    "all_df['HeatingQC']     = labelencoder.fit_transform(all_df['HeatingQC'])   \n",
    "all_df['CentralAir']    = labelencoder.fit_transform(all_df['CentralAir'])   \n",
    "all_df['Electrical']    = labelencoder.fit_transform(all_df['Electrical'])    \n",
    "all_df['GarageType']    = labelencoder.fit_transform(all_df['GarageType'])  \n",
    "all_df['GarageFinish']  = labelencoder.fit_transform(all_df['GarageFinish'])   \n",
    "all_df['GarageQual']    = labelencoder.fit_transform(all_df['GarageQual'])  \n",
    "all_df['GarageCond']    = labelencoder.fit_transform(all_df['GarageCond'])   \n",
    "all_df['PavedDrive']    = labelencoder.fit_transform(all_df['PavedDrive'])  \n",
    "all_df['SaleCondition'] = labelencoder.fit_transform(all_df['SaleCondition'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8820a1f",
   "metadata": {
    "papermill": {
     "duration": 0.006649,
     "end_time": "2024-10-07T20:52:29.023668",
     "exception": false,
     "start_time": "2024-10-07T20:52:29.017019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Feature scaling:** \n",
    "is a preprocessing step in machine learning that adjusts the range of values for features (input variables) in your dataset. The goal is to ensure that the features contribute equally to the model training process by bringing them to a comparable scale. This is important because many machine learning algorithms (e.g., gradient-based methods like logistic regression, neural networks, and support vector machines) are sensitive to the scale of input data.\n",
    "\n",
    "**Here we are using Standardization:**\n",
    "It transforms the data such that its mean is 0 and its standard deviation is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1527f28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:29.039047Z",
     "iopub.status.busy": "2024-10-07T20:52:29.038657Z",
     "iopub.status.idle": "2024-10-07T20:52:29.064590Z",
     "shell.execute_reply": "2024-10-07T20:52:29.063087Z"
    },
    "papermill": {
     "duration": 0.036756,
     "end_time": "2024-10-07T20:52:29.067218",
     "exception": false,
     "start_time": "2024-10-07T20:52:29.030462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#scales features by removing the mean\n",
    "Scaler = StandardScaler()\n",
    "# \".fit_transform()\" calculates the mean and standard deviation for scaling and then applies the transformation to the entire dataset (all_df)\n",
    "all_scaled   = pd.DataFrame(Scaler.fit_transform(all_df))\n",
    "#spliting th data into 50/50 :1460 -> firt 1460, 1460:2920 -> second 1460.\n",
    "#as the training set consists of the first 1460 rows (train_scaled), while the test set is the next 1460 rows (test_scaled)\n",
    "#train_scaled: This represents the feature set after feature scaling, which contains all the predictors (i.e., features)\n",
    "train_scaled = pd.DataFrame(all_scaled[:1460])\n",
    "test_scaled  = pd.DataFrame(all_scaled[1460:2920])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d14d3853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:29.083621Z",
     "iopub.status.busy": "2024-10-07T20:52:29.083159Z",
     "iopub.status.idle": "2024-10-07T20:52:29.093157Z",
     "shell.execute_reply": "2024-10-07T20:52:29.092001Z"
    },
    "papermill": {
     "duration": 0.02147,
     "end_time": "2024-10-07T20:52:29.095580",
     "exception": false,
     "start_time": "2024-10-07T20:52:29.074110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X is the feature set\n",
    "# \"train_test_split\" is a Sklearn function to splits datasets into training and testing sets\n",
    "# \"y['SalePrice']\" is the target variable it was previously separated into the y DataFrame.\n",
    "# \"test_size=0.1\" -> 10% of the data will be used as a test set, the other 90% for training\n",
    "# X_train: 90% of the features, used for training your model.\n",
    "# X_test: 10% of the features, used for testing your model's performance.\n",
    "# y_train: 90% of the target values corresponding to X_train.\n",
    "# y_test: 10% of the target values corresponding to X_test.\n",
    "# x -> input (Features), y -> output (\"SalePrice\")\n",
    "\n",
    "X = train_scaled\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y['SalePrice'], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7097ef8",
   "metadata": {
    "papermill": {
     "duration": 0.006775,
     "end_time": "2024-10-07T20:52:29.109583",
     "exception": false,
     "start_time": "2024-10-07T20:52:29.102808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3974c950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:29.125083Z",
     "iopub.status.busy": "2024-10-07T20:52:29.124674Z",
     "iopub.status.idle": "2024-10-07T20:52:30.325111Z",
     "shell.execute_reply": "2024-10-07T20:52:30.323763Z"
    },
    "papermill": {
     "duration": 1.211262,
     "end_time": "2024-10-07T20:52:30.327712",
     "exception": false,
     "start_time": "2024-10-07T20:52:29.116450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=2, max_leaves=None,\n",
       "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=1000, n_jobs=-1,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "XGB = XGBRegressor(\n",
    "    max_depth=2,       #maximum depth tree (Limits the depth of each decision tree to prevent overfitting)\n",
    "    learning_rate=0.1, #step size to update the weight after each boosting step (Controls how much the model adjusts during each boosting step)\n",
    "    n_estimators=1000, #number of trees or \"boosting rounds\"\n",
    "    reg_alpha=0.001,   #regulization term on weights\n",
    "    reg_lambda=0.000001,\n",
    "    n_jobs=-1,         #uses all availible CPU \n",
    "    min_child_weight=3 #minimum sum of instance weights required in a child note\n",
    ")                      #^^(A higher value makes the model more conservative by preventing the tree from growing too complex )\n",
    "XGB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e8aa4",
   "metadata": {
    "papermill": {
     "duration": 0.007048,
     "end_time": "2024-10-07T20:52:30.342807",
     "exception": false,
     "start_time": "2024-10-07T20:52:30.335759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## LGBM\n",
    "Using both LGBM and XGB in your modeling pipeline can be beneficial for comparison purposes, but it is not necessary. However here we are going to use the prediction from both models and combine them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19d4d612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:30.359431Z",
     "iopub.status.busy": "2024-10-07T20:52:30.358949Z",
     "iopub.status.idle": "2024-10-07T20:52:36.152916Z",
     "shell.execute_reply": "2024-10-07T20:52:36.151745Z"
    },
    "papermill": {
     "duration": 5.805072,
     "end_time": "2024-10-07T20:52:36.155448",
     "exception": false,
     "start_time": "2024-10-07T20:52:30.350376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3497\n",
      "[LightGBM] [Info] Number of data points in the train set: 1314, number of used features: 71\n",
      "[LightGBM] [Info] Start training from score 180704.734399\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMRegressor(n_estimators=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(n_estimators=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMRegressor(n_estimators=1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "#initialize model\n",
    "#n_estimators=1000 specifies that the model will build 1000 boosting iterations or \"trees\"\n",
    "LGBM = LGBMRegressor(n_estimators = 1000)\n",
    "LGBM.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e596abb5",
   "metadata": {
    "papermill": {
     "duration": 0.0071,
     "end_time": "2024-10-07T20:52:36.170041",
     "exception": false,
     "start_time": "2024-10-07T20:52:36.162941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "414b47e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:36.187439Z",
     "iopub.status.busy": "2024-10-07T20:52:36.186251Z",
     "iopub.status.idle": "2024-10-07T20:52:36.447691Z",
     "shell.execute_reply": "2024-10-07T20:52:36.446307Z"
    },
    "papermill": {
     "duration": 0.273186,
     "end_time": "2024-10-07T20:52:36.450594",
     "exception": false,
     "start_time": "2024-10-07T20:52:36.177408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9871212797046796 Test Score: 0.920257100589606\n",
      "Training score: 0.9999557727264998 Test Score: 0.9101390980189892\n"
     ]
    }
   ],
   "source": [
    "#Test score for both models \n",
    "print (\"Training score:\",XGB.score(X_train,y_train), \"Test Score:\",XGB.score(X_test,y_test))\n",
    "print (\"Training score:\",LGBM.score(X_train,y_train),\"Test Score:\",LGBM.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd96619",
   "metadata": {
    "papermill": {
     "duration": 0.007742,
     "end_time": "2024-10-07T20:52:36.466836",
     "exception": false,
     "start_time": "2024-10-07T20:52:36.459094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c76f6144",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:36.485185Z",
     "iopub.status.busy": "2024-10-07T20:52:36.484774Z",
     "iopub.status.idle": "2024-10-07T20:52:36.732478Z",
     "shell.execute_reply": "2024-10-07T20:52:36.731113Z"
    },
    "papermill": {
     "duration": 0.260783,
     "end_time": "2024-10-07T20:52:36.736117",
     "exception": false,
     "start_time": "2024-10-07T20:52:36.475334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#generate the predictions using \".predict\" for the \"test_scaled\" for both models and store it to merge later\n",
    "y_pred_xgb  = pd.DataFrame( XGB.predict(test_scaled))\n",
    "y_pred_lgbm = pd.DataFrame(LGBM.predict(test_scaled))\n",
    "#create empty dataset set to store the result (with the same format as the sample_submission)\n",
    "y_pred=pd.DataFrame()\n",
    "#store the \"SalePrice\" prediction from both XGB and LGBM \n",
    "#the SalePrice was combines by dividng each value from each model half and then added together\n",
    "# so if for Id 1 the SalePrice prediction from XGB was 98 and LGBM was 102 that would be 100 ((98/2)+(102/2))=100 \n",
    "y_pred['SalePrice'] = 0.5 * y_pred_xgb[0] + 0.5 * y_pred_lgbm[0]\n",
    "#store the Id column in the dataset\n",
    "y_pred['Id'] = test['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "240f51cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T20:52:36.753372Z",
     "iopub.status.busy": "2024-10-07T20:52:36.752909Z",
     "iopub.status.idle": "2024-10-07T20:52:36.767455Z",
     "shell.execute_reply": "2024-10-07T20:52:36.766043Z"
    },
    "papermill": {
     "duration": 0.026574,
     "end_time": "2024-10-07T20:52:36.770473",
     "exception": false,
     "start_time": "2024-10-07T20:52:36.743899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save dataset into a csv file for submission\n",
    "y_pred.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868283,
     "sourceId": 5407,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.60631,
   "end_time": "2024-10-07T20:52:37.501590",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-07T20:52:22.895280",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
